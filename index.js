// íŒ¨í‚¤ì§€ ê°€ì ¸ì˜¤ê¸°
import express from "express";
import cors from "cors";
import OpenAI from "openai";
import * as dotenv from "dotenv";

const app = express();

app.use(cors());

// í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë°›ì€ jsoní˜•íƒœì˜ ë°ì´í„°ë¥¼ ìë°”ìŠ¤í¬ë¦½íŠ¸ ê°ì²´ë¡œ ë³€ê²½(íŒŒì‹±)í•´ì£¼ëŠ” ì½”ë“œ
app.use(express.json()); // for parsing application/json
app.use(express.urlencoded({ extended: true })); // for parsing application/x-www-form-urlencoded

// env ì„¤ì •
dotenv.config(); //í™˜ê²½ë³€ìˆ˜ ë¡œë“œ

// openai ì •ë³´ ì„¤ì •
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

console.log(process.env.OPENAI_API_KEY);

// ì±—ë´‡ apiì„¤ì •
const initialMessage = (ingredientList) => {
  return [
    {
      role: "system",
      content: `ë‹¹ì‹ ì€ "ë§›ìˆëŠ” ì‰í”„"ë¼ëŠ” ì´ë¦„ì˜ ì „ë¬¸ ìš”ë¦¬ì‚¬ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì¬ë£Œ ëª©ë¡ì„ ì œê³µí•˜ë©´, ì²«ë²ˆì§¸ ë‹µë³€ì—ì„œëŠ” ì˜¤ì§ ë‹¤ìŒ ë¬¸ì¥ë§Œì„ ì‘ë‹µìœ¼ë¡œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì–´ë–¤ ì •ë³´ë„ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”: ì œê³µí•´ì£¼ì‹  ì¬ë£Œ ëª©ë¡ì„ ë³´ë‹ˆ ì •ë§ ë§›ìˆëŠ” ìš”ë¦¬ë¥¼ ë§Œë“¤ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”. ì–´ë–¤ ì¢…ë¥˜ì˜ ìš”ë¦¬ë¥¼ ì„ í˜¸í•˜ì‹œë‚˜ìš”? ê°„ë‹¨í•œ í•œë¼ ì‹ì‚¬, íŠ¹ë³„í•œ ì €ë… ë©”ë‰´, ì•„ë‹ˆë©´ ê°€ë²¼ìš´ ê°„ì‹ ë“± êµ¬ì²´ì ì¸ ì„ í˜¸ë„ê°€ ìˆìœ¼ì‹œë‹¤ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”. ê·¸ì— ë§ì¶° ìµœê³ ì˜ ë ˆì‹œí”¼ë¥¼ ì œì•ˆí•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤!`,
    },
    {
      role: "user",
      content: `ì•ˆë…•í•˜ì„¸ìš”, ë§›ìˆëŠ” ì‰í”„ë‹˜. ì œê°€ ê°€ì§„ ì¬ë£Œë¡œ ìš”ë¦¬ë¥¼ í•˜ê³  ì‹¶ì€ë° ë„ì™€ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”? ì œ ëƒ‰ì¥ê³ ì— ìˆëŠ” ì¬ë£Œë“¤ì€ ë‹¤ìŒê³¼ ê°™ì•„ìš”: ${ingredientList
        .map((item) => item.value)
        .join(", ")}`,
    },
  ];
};

// ì´ˆê¸° ë‹µë³€
// create recipe
app.post("/recipe", async (req, res) => {
  const { ingredientList } = req.body; // í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì¬ë£Œ ëª©ë¡ì„ ë°›ìŒ
  const messages = initialMessage(ingredientList);
  console.log("ğŸš€ ~ messages:", messages);
  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages,
      temperature: 1,
      max_tokens: 4000,
      top_p: 1,
    });
    const data = [...messages, response.choices[0].message];
    console.log("data", data);
    res.json({ data });
  } catch (error) {
    console.log(error);
  }
});

// ìœ ì €ì™€ì˜ ì±„íŒ…
// create chat
app.post("/message", async (req, res) => {
  const { userMessage, messages } = req.body;

  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [...messages, userMessage],
      temperature: 1,
      max_tokens: 4000,
      top_p: 1,
    });
    const data = response.choices[0].message;
    res.json({ data });
  } catch (error) {
    console.log(error);
  }
});

// í…ŒìŠ¤íŠ¸ìš© api
// req: í”„ë¡ íŠ¸ -> ë°±ì—”ë“œ [ìš”ì²­ê°ì²´]
// res: ë°±ì—”ë“œ -> í”„ë¡ íŠ¸ [ì‘ë‹µê°ì²´]
// read test
app.get("/test", (req, res) => {
  // ì´ apiê°€ í˜¸ì¶œë˜ì—ˆì„ ë•Œ ì‹¤í–‰ë˜ëŠ” ë¡œì§
  // try-catchë¬¸ : ì—ëŸ¬ê°€ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì½”ë“œë¥¼ ì•ˆì „í•˜ê²Œ ì‹¤í–‰í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” êµ¬ë¬¸
  try {
    // ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” ì½”ë“œ(í”„ë¡ íŠ¸ ì—”ë“œì—ê²Œ ì‘ë‹µ)
    res.json({ data: "test" });
  } catch (error) {
    // ì—ëŸ¬ê°€ ë°œìƒí–ˆì„ ë•Œ ì‹¤í–‰ë˜ëŠ” ì½”ë“œ
    console.error("Error occurred:", error);
  }
});

app.listen(8080, () => {
  console.log("Server is running on port 8080");
});

// react : 3000ë²ˆ í¬íŠ¸
// express : 8080ë²ˆ í¬íŠ¸
// url : localhost:8080
